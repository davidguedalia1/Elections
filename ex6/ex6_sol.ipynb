{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex6_sol.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyQ45Phps6Z6"
      },
      "source": [
        "**Ex *6*- Statistics Lab**\n",
        "\n",
        "The Solution of the exercise in the bottom as Q1 is continuing of Lab 5.\n",
        "\n",
        "Erel Rojanski, David Guedalia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRKSr5EstAUm",
        "outputId": "b32d4883-19c1-4454-a849-fb8092e2634a"
      },
      "source": [
        "# Add a check if we run in google colab or locally in jupyter notebook\n",
        "run_in_colab = False\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    run_in_colab = True\n",
        "    print('Running on CoLab')\n",
        "else:\n",
        "    print('Running locally on Jupyter')\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CoLab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC0NlMvHzL1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2018b1cc-bfe8-432a-bdbb-530e531ad5ad"
      },
      "source": [
        "import sys\n",
        "import numpy as np  # a module for working with numerical array \n",
        "import pandas as pd  # a module for working with data-frames\n",
        "import statsmodels.api as sm  # a module for statistical modelling (e.g. regression analysis)\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from heapq import nlargest\n",
        "from sklearn.preprocessing import normalize\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGTS_zCRZGfV"
      },
      "source": [
        "First, we need to mount our local drive to the colab network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWSJpsyKqHjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "273a5fca-7a9d-40bd-c73b-f7ed3018b443"
      },
      "source": [
        "# Mount drive in google colab\n",
        "if run_in_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "else:  # Set local path \n",
        "    data_path = \"C:/Users/Or Zuk/Google Drive/HUJI/Teaching/Lab_52568/Data/Elections/\"  \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaG-KYCw8XZz",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "3795e6ee-f737-4a18-fb53-ed5d91d218b5"
      },
      "source": [
        "# Loading elections 2021 elections data:\n",
        "if run_in_colab:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eef363cf-bb64-430e-85b5-694a0e755424\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-eef363cf-bb64-430e-85b5-694a0e755424\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving eshkol_hevrati_calcali.xlsx to eshkol_hevrati_calcali (4).xlsx\n",
            "Saving votes per ballot 2021.csv to votes per ballot 2021 (3).csv\n",
            "Saving votes per city 2020.csv to votes per city 2020 (2).csv\n",
            "Saving votes per city 2021.csv to votes per city 2021 (4).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxK5YlBH1geD"
      },
      "source": [
        "# Loading elections 2021 elections data:\n",
        "import io\n",
        "\n",
        "data_type = \"city\" # \"ballot\"  # city\n",
        "if run_in_colab:\n",
        "    if data_type == \"ballot\":\n",
        "      df_2021_raw = pd.read_csv(io.BytesIO(uploaded['votes per city 2021.csv']),  encoding = 'iso-8859-8', index_col='שם ישוב')\n",
        "    else:\n",
        "      df_2021_raw = pd.read_csv(io.BytesIO(uploaded['votes per city 2021.csv']),  encoding = 'iso-8859-8', index_col='שם ישוב')\n",
        "      df_2020_raw = pd.read_csv(io.BytesIO(uploaded['votes per city 2020.csv']),  encoding = 'iso-8859-8', index_col='שם ישוב')\n",
        "else:  # read local file\n",
        "    if data_type == \"ballot\":\n",
        "        df_2021_raw = pd.read_csv(data_path + 'votes per ballot 2021.csv',  encoding = 'iso-8859-8', index_col='שם ישוב')\n",
        "    else:\n",
        "        df_2021_raw = pd.read_csv(data_path + 'votes per city 2021.csv',  encoding = 'iso-8859-8', index_col='שם ישוב')\n",
        "\n",
        "\n",
        "df_2021 = df_2021_raw.drop('סמל ועדה', axis=1)\n",
        "df_2021 = df_2021[df_2021.columns[5:-1]] # removing \"metadata\" columns\n",
        "df_2020 = df_2020_raw.drop('סמל ועדה', axis=1)\n",
        "df_2020 = df_2020[df_2020.columns[5:-1]] # removing \"metadata\" columns\n"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVfhjKgS16sL"
      },
      "source": [
        "\n",
        "# df_2021.reset_index(inplace=True)\n",
        "# df_2021.style.set_properties(**{'text-align': 'left'})\n",
        "# df_2021.head()\n",
        "\n",
        "# df_2020.style.set_properties(**{'text-align': 'left'})\n",
        "# df_2020.head()\n",
        "# Compute votes share only for parties above a certain threshold \n",
        "def parties_votes_percents(df, thresh):\n",
        "    par = df.sum().div(df.sum().sum()).sort_values(ascending=False)\n",
        "    return par[par > thresh]\n",
        "print(df_2021.columns)\n",
        "print(df_2020.columns)\n",
        "\n",
        "total_votes_2021 = parties_votes_percents(df_2021, 0.035)  # total votes for each party\n",
        "names_2021 = total_votes.keys() # largest parties\n",
        "total_votes_2020 = parties_votes_percents(df_2020, 0.035)  # total votes for each party\n",
        "names_2020 = total_votes.keys() # largest parties\n",
        "# Data with only the largest parties:\n",
        "df_2021 = df_2021[names]\n",
        "df_cities = df_2021\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyqd8VkhsWjs"
      },
      "source": [
        "## Question 1: \n",
        "\n",
        "A function that calculates the new design matrix of size C * (K + C) and returns it\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYYWx3mDsW-_"
      },
      "source": [
        "# gets df of size C * K and return s size c * (K+C) when X[i][k+i] = sigma{1<j<k}(df[i][j])\n",
        "def enlarge_df(df): \n",
        "    sums = np.sum(df_cities, axis=1) # X[i][k+i] = sigma{1<j<k}(df[i][j])\n",
        "    fill_mat = np.zeros((df.shape[0], df.shape[0])).astype(int)\n",
        "    np.fill_diagonal(fill_mat, sums) # C * C mat with diagonal of sigma\n",
        "    fill_df = pd.DataFrame(fill_mat, index=df.index.tolist()) # setting matching indexes\n",
        "    full_df = pd.concat([df, fill_df], axis=1, join=\"inner\") # connecting the df's\n",
        "    return full_df\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzcWpoQ1sXyq"
      },
      "source": [
        "Regression function from lab 4:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZXjKlS7sYOK"
      },
      "source": [
        "# Correct for voting turnout in cities/ballots using linear regression\n",
        "def regression_turnout_correction(df, turnout):\n",
        "    # Preprocess: remove cities/ballots with zero votes:\n",
        "    good_inds = np.where(np.array(turnout) > 0)\n",
        "    if np.min(turnout) == 0:\n",
        "      print(\"Removed cities with no votes in simulation\")\n",
        "    df = df.iloc[good_inds]\n",
        "    turnout = turnout.iloc[good_inds]\n",
        "\n",
        "    p = df.sum().div(df.sum().sum())  # votes without correction\n",
        "    bzb = df.sum(axis=1) / turnout # can also be read from outside\n",
        "    model = sm.OLS(bzb, df).fit() # linear regression WITHOUT intercept\n",
        "    q_hat = p * model.params  # M.coef_ # beta_inv\n",
        "    q_hat = q_hat / q_hat.sum()  # Normalize\n",
        "    return [p, q_hat, model.params] # beta_inv"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-a3S_TVsY8A"
      },
      "source": [
        "New regression function that works with 2 parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mPze1-HsZKv"
      },
      "source": [
        "\n",
        "# Correct for voting turnout in cities/ballots using linear regression\n",
        "def regression_turnout_correction_2params(df, turnout):\n",
        "    \n",
        "    # Preprocess: remove cities/ballots with zero votes:\n",
        "    good_inds = np.where(np.array(turnout) > 0)\n",
        "    if np.min(turnout) == 0:\n",
        "      print(\"Removed cities with no votes in simulation\")\n",
        "    df = df.iloc[good_inds]\n",
        "    turnout = turnout.iloc[good_inds]\n",
        "    df_big = enlarge_df(df)\n",
        "    p = df.sum().div(df.sum().sum())  # votes without correction\n",
        "    bzb = df.sum(axis=1) / turnout # can also be read from outside\n",
        "    model = sm.OLS(bzb, df_big).fit() # linear regression WITHOUT intercept\n",
        "\n",
        "    big_params = model.params\n",
        "    beta = big_params[:df_big.shape[1] - df_big.shape[0]]\n",
        "    alpha = big_params[df_big.shape[1] - df_big.shape[0]:]\n",
        "    beta_mat = np.tile(beta, (alpha.shape[0], 1))\n",
        "    alpha_mat = np.tile(alpha, (beta.shape[0], 1)).T\n",
        "    final_params = beta_mat + alpha_mat\n",
        "    n_hat_tilde = df * final_params\n",
        "    q_hat = np.sum(n_hat_tilde, axis=0)\n",
        "    q_hat = q_hat / np.sum(q_hat)\n",
        "    return [p, q_hat, final_params] # beta_inv\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEfpvIHTstSB"
      },
      "source": [
        "## Question 2: \n",
        "#### Repeat the simulations same as in lab 3, and add to the graphs the estimator with the new fixing parameter\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t_qtfK6stfv"
      },
      "source": [
        "**From** lab 4: \n",
        "Function that recieves the  $\\tilde{N}$ and V matrices and samples binomial votes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFMmjvzHswxi"
      },
      "source": [
        "def sim_data(N,V):\n",
        "  new_df = pd.DataFrame(np.random.binomial(N,V))\n",
        "  new_df.index = df_2021.index\n",
        "  v = new_df.sum(axis=1)/ N.sum(axis=1)\n",
        "  return new_df, v"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62zmCIF4sx5h"
      },
      "source": [
        "#### Run simulations and apply corrections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfyKGXZbsyCS"
      },
      "source": [
        "Computing  $\\tilde{N}$ and $V_i$ for the 3 simulations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcIEbn6nsyQB"
      },
      "source": [
        "# Nij~ :\n",
        "N_tilde = np.array(df_2021.mul(df_2021_raw['בזב'].sum()).div(df_2021_raw['כשרים'].sum()),dtype='int32')\n",
        "print(N_tilde.shape)\n",
        "print(df_2021.shape)\n",
        "# 3 types of Vi \n",
        "v = df_2021_raw['כשרים'].div(df_2021_raw['בזב'])\n",
        "u = list(np.random.permutation(0.2 + np.array(range(13)) * 0.05))\n",
        "#u = [0.6,0.65,0.75,0.5,0.4,0.35,0.8,0.55,0.45,0.25,0.3,0.7,0.2]\n",
        "#u_random = random.sample(u, len(u))\n",
        "\n",
        "dim = df_2021.shape\n",
        "# converting them to the desired shape:\n",
        "V_v = np.tile(np.array([v]).transpose(), (1, len(names)))\n",
        "V_u = np.tile(np.array(u), (dim[0],1))\n",
        "#V_u_random = np.tile(np.array(u_random), (dim[0],1))\n",
        "\n",
        "V_u_random = V_u.copy()\n",
        "for i in range(df_2021.shape[0]):\n",
        "  V_u_random[i,] = np.random.permutation(u)\n",
        "#V_u_random = np.tile(np.array(u_random), (dim[0],1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhtylBknszVo"
      },
      "source": [
        "A function that calculates the $p$ and the  $\\hat{q}$  (after fixing data to 100% votes with $v_i= \\frac{kosher_i}{bzb_i}$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7-DJpx7szgT"
      },
      "source": [
        "def turnout_correction(df, fix_param):\n",
        "  p = parties_votes_percents(df, 0) \n",
        "  q_hat = parties_votes_percents(df.div(fix_param, axis = \"rows\"), 0)\n",
        "  return q_hat\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1ZiIP8xszsL"
      },
      "source": [
        "Multiple simulations function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SePUAKJesz27"
      },
      "source": [
        "def simulations(iters,N,V):\n",
        "  p_mat = np.zeros([iters, len(names)])\n",
        "  q_hat = np.zeros([iters, len(names)]) \n",
        "  q_hat_reg = np.zeros([iters, len(names)]) \n",
        "\n",
        "  q_hat_reg_new = np.zeros([iters, len(names)]) \n",
        "  p_mat_new = np.zeros([iters, len(names)])\n",
        "\n",
        "\n",
        "  # in every simulation we calculate p and q_hat (after fixing the data)\n",
        "  for i in range(0,iters):\n",
        "    new_df, v = sim_data(N,V)\n",
        "    q_hat[i,] = turnout_correction(new_df, v)\n",
        "    p_mat[i,], q_hat_reg[i,] = regression_turnout_correction(new_df, v)[0:2]\n",
        "    p_mat_new[i,], q_hat_reg_new[i,] = regression_turnout_correction_2params(new_df, v)[0:2]\n",
        "\n",
        "  return [p_mat, q_hat, q_hat_reg, p_mat_new, q_hat_reg_new]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37RvRD_Gs1BF"
      },
      "source": [
        " Run 50 simulations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCOuACpUs1P2"
      },
      "source": [
        "iters = 1 # number of simulations\n",
        "q_real = N_tilde.sum(axis=0)/(N_tilde.sum())\n",
        "sim_v = simulations(iters, N_tilde, V_v)\n",
        "mean_p_v = np.nanmean(sim_v[0],axis=0)\n",
        "mean_q_v = np.nanmean(sim_v[1],axis=0)\n",
        "mean_q_v_beta = np.nanmean(sim_v[2],axis=0)\n",
        "std_q_v = np.std(sim_v[1],axis=0) # Compute also standard deviations \n",
        "std_q_v_beta = np.std(sim_v[2],axis=0)\n",
        "\n",
        "mean_p_v2 = np.nanmean(sim_v[3],axis=0)\n",
        "mean_q_v_beta2 = np.nanmean(sim_v[4],axis=0)\n",
        "std_q_v_beta2 = np.std(sim_v[4],axis=0)\n",
        "\n",
        "\n",
        "sim_u = simulations(iters, N_tilde, V_u)\n",
        "mean_p_u = sim_u[0].mean(axis=0) \n",
        "mean_q_u = sim_u[1].mean(axis=0) \n",
        "mean_q_u_beta = sim_u[2].mean(axis=0)\n",
        "std_q_u = sim_u[1].std(axis=0) \n",
        "std_q_u_beta = sim_u[2].std(axis=0)\n",
        "\n",
        "mean_p_u2 = sim_u[3].mean(axis=0) \n",
        "mean_q_u_beta2 = sim_u[4].mean(axis=0)\n",
        "std_q_u_beta2 = sim_u[4].std(axis=0)\n",
        "\n",
        "\n",
        "sim_u_random = simulations(iters, N_tilde, V_u_random)\n",
        "mean_p_u_random = sim_u_random[0].mean(axis=0)\n",
        "mean_q_u_random = sim_u_random[1].mean(axis=0)\n",
        "mean_q_u_random_beta = sim_u_random[2].mean(axis=0)\n",
        "std_q_u_random = sim_u_random[1].std(axis=0)\n",
        "std_q_u_random_beta = sim_u_random[2].std(axis=0)\n",
        "\n",
        "mean_p_u_random = sim_u_random[3].mean(axis=0)\n",
        "mean_q_u_random_beta2 = sim_u_random[4].mean(axis=0)\n",
        "std_q_u_random_beta2 = sim_u_random[4].std(axis=0)\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX26VzGws1Yq"
      },
      "source": [
        "## Bar-plots showing the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Ob8uxms1iO"
      },
      "source": [
        "# Bar plot for a party, only showing values above a certain threshold after fixing:\n",
        "def party_bar_fix(q_real, q_hat, q_hat_beta, q_hat_std, q_hat_beta_std, p, q_hat_beta2, q_hat_beta_std2,):\n",
        "    width = 0.15  # set column width \n",
        "    n = len(total_votes)\n",
        "\n",
        "    rev_names = [name[::-1] for name in list(names)]\n",
        "    fig, ax = plt.subplots(figsize=(10, 4))  # plt.subplots()\n",
        "\n",
        "    q_real_bar = ax.bar(np.arange(n), list(q_real), width, color='b')\n",
        "    q_hat_bar = ax.bar(np.arange(n)+width, q_hat, width, color='r', yerr = q_hat_std, capsize=5)\n",
        "    q_hat_beta_bar = ax.bar(np.arange(n)+2*width, q_hat_beta, width, color='y', yerr = q_hat_beta_std, capsize=5)\n",
        "    p_bar = ax.bar(np.arange(n)+3*width, p, width, color='g')\n",
        "    q_hat_beta_bar_new = ax.bar(np.arange(n)+4*width, q_hat_beta2, width, color='brown', yerr = q_hat_beta_std2, capsize=5)\n",
        "\n",
        "\n",
        "    ax.set_ylabel('Votes percent')\n",
        "    ax.set_xlabel('Parties Names')\n",
        "    ax.set_title('Votes percent per party - simultions')\n",
        "    ax.set_xticks(np.arange(n))\n",
        "    ax.set_xticklabels(rev_names, rotation=90)\n",
        "    ax.legend((q_real_bar, q_hat_bar, q_hat_beta_bar, p_bar, q_hat_beta_bar_new), ('q real', 'q hat', 'q hat beta', 'p', 'q hat beta 2 params'))\n",
        "    plt.show()\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "party_bar_fix(q_real, mean_q_v, mean_q_v_beta, std_q_v, std_q_v_beta, mean_p_v, mean_q_v_beta2, std_q_v_beta2)\n",
        "party_bar_fix(q_real, mean_q_u, mean_q_u_beta, std_q_u, std_q_u_beta, mean_p_u, mean_q_u_beta2, std_q_u_beta2)\n",
        "party_bar_fix(q_real, mean_q_u_random, mean_q_u_random_beta, std_q_u_random, std_q_u_random_beta, mean_p_u_random, mean_q_u_random_beta2, std_q_u_random_beta2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvV5Hx6o5L88"
      },
      "source": [
        "In the first case, it is very clear that the 2 params regression is better, it doesnt have any negative values that are incorrect and it is much closer to the q_real and q_hat. its disadvantage is that it has a higher std.\n",
        "\n",
        "In the second case, its a hard choice because the are both simillar in how much they are close but the 2 params regression has a lower std.\n",
        "\n",
        "In the third case it is also pretty clear that the 2 params regression is a better fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzqZqF6ryYCr"
      },
      "source": [
        "if   run_in_colab:\n",
        "    df_2021_raw = pd.read_csv(io.BytesIO(uploaded['votes per ballot 2021.csv']),  encoding = 'iso-8859-8', index_col='שם ישוב')\n",
        "\n",
        "df_2021_raw = df_2021_raw[df_2021_raw.index != 'מעטפות חיצוניות']\n",
        "df_2021 = df_2021_raw\n",
        "df_2021 = df_2021[df_2021.columns[10:-1]] # removing \"metadata\" columns\n",
        "\n",
        "names_passed = total_votes.keys()\n",
        "df_cities = df_2021\n",
        "\n",
        "df_2021_passed = df_2021[names_passed]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgO8DvtQMHfj"
      },
      "source": [
        "**Question** **3**:\n",
        "**Section A**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ii0F4s2MHRM"
      },
      "source": [
        "# PCA of the two main components.\n",
        "pca = PCA(n_components=2)\n",
        "df_2021_transform = df_2021.T\n",
        "\n",
        "# PCA fit.\n",
        "pca_a = pca.fit_transform(df_2021_transform)\n",
        "fig, ax = plt.subplots(figsize=(20,20))\n",
        "first = pca_a[:,0]\n",
        "second = pca_a[:,1]\n",
        "\n",
        "ax.scatter(first, second)\n",
        "ax.set_xlabel('first component pc', fontsize=16)\n",
        "ax.set_ylabel('second component pc', fontsize=16)\n",
        "ax.set_title('Only two dimension pca', fontsize=16)\n",
        "names = df_2021.columns\n",
        "\n",
        "numner_of_parties = len(names)\n",
        "correction_names = [x[::-1] for x in names]\n",
        "\n",
        "for i in range(numner_of_parties):\n",
        "    ax.annotate(correction_names[i], (first[i], second[i]), fontsize=20)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqP4pDhlVzRq"
      },
      "source": [
        "Answer Section A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DG5Bnh6WWMa"
      },
      "source": [
        "Answer Section A:\n",
        "\n",
        "We make the subpot much bigger to see the parties, and we can see that the left parties are close and also the arabic parties are very close to each other.\n",
        "Also we can see as we go to the right we can see parties more right-wing views.\n",
        "Butin the other hand, we can see results that are unexpected such as \"Tikva Hadasha\" is near to the left parties as \"Avoda\", \"Meretz\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAOScPm2WItq"
      },
      "source": [
        "**Question** **3**:\n",
        "\n",
        "**Section B**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9hI8Ls8hVJq"
      },
      "source": [
        "\n",
        "df_2021_n = normalize(df_2021, axis = 0)\n",
        "\n",
        "# PCA of the two main components.\n",
        "df_2021_n_transform = df_2021_n.T\n",
        "\n",
        "# PCA fit.\n",
        "pca_a_n = pca.fit_transform(df_2021_n_transform)\n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "first_n = pca_a_n[:,0]\n",
        "second_n = pca_a_n[:,1]\n",
        "\n",
        "ax.scatter(first_n, second_n)\n",
        "ax.set_xlabel('first component pc', fontsize=18)\n",
        "ax.set_ylabel('second component pc', fontsize=18)\n",
        "ax.set_title('Only two dimension pca', fontsize=18)\n",
        "\n",
        "numner_of_parties = len(names)\n",
        "correction_names = [x[::-1] for x in names]\n",
        "\n",
        "for i in range(numner_of_parties):\n",
        "    ax.annotate(correction_names[i], (first_n[i],second_n[i]), fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-WtJ8ChXvUN"
      },
      "source": [
        "Answer Section B:\n",
        "\n",
        "We can see better results from section A - first we can see much better the parties that didnt pass the threshold and they are close to each other, We can see the arabic parties close to each other- The centarl-left parties also close to each other.\n",
        "And the Charidi parties close to each other in the top of the graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t8ThqF06Lt1"
      },
      "source": [
        "if  run_in_colab:\n",
        "    df_socio= pd.read_excel(io.BytesIO(uploaded['eshkol_hevrati_calcali.xlsx']), index_col='name')\n",
        "else:\n",
        "    df_socio= pd.read_excel('eshkol_hevrati_calcali.xlsx', index_col='name')\n",
        "\n",
        "df_2021_raw = df_2021_raw[df_2021_raw.columns[0:-1]]\n",
        "merged_df = df_2021_raw.join(df_socio.set_index('set_code'), on='סמל ישוב')\n",
        "merged_df = merged_df.dropna()\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7hJrXP816-0"
      },
      "source": [
        "**Question** **4**:\n",
        "\n",
        "**Section A**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuAkuhcP18mW"
      },
      "source": [
        "merged_df_names = merged_df[names]\n",
        "\n",
        "merged_n = normalize(merged_df_names.T, axis=0)\n",
        "\n",
        "pca_4 = pca.fit_transform(merged_n.T)\n",
        "first_n = pca_4[:,0]\n",
        "second_n = pca_4[:,1]\n",
        "fig, ax = plt.subplots(figsize=(16,12))\n",
        "sc = ax.scatter(first_n, second_n, c = merged_df['eco_level'], s=4)\n",
        "plt.colorbar(sc)\n",
        "ax.set_xlabel('first pca', fontsize=16)\n",
        "ax.set_ylabel('second pca', fontsize=16)\n",
        "ax.set_title('2 dimension pca',  fontsize=24)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Oe6UldUUwVz"
      },
      "source": [
        "Answer Section A:\n",
        "\n",
        "First of all we can see there is three groups in the graph - Charedis, Arabics, Rest.\n",
        "were we can see the highst and left you go you will find better economic-social, and you will find more support for parties of the left side and if you will go down and left you will find average economic-social but if you will go to the right you will find a bad economic-social were is the Arabics kalpi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkFggJS5ygGT"
      },
      "source": [
        "**Question** **4**:\n",
        "\n",
        "**Section B**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IvPScE8yfjI"
      },
      "source": [
        "PARTIES = 13\n",
        "correction_names_passed = [x[::-1] for x in names_passed]\n",
        "fig, ax = plt.subplots(4, 4, figsize=(30,30))\n",
        "\n",
        "support_arr = []\n",
        "for i in range(PARTIES): \n",
        "  party = names_passed[i]\n",
        "  vec_party = merged_df[party]\n",
        "  support_party = vec_party.div(merged_df['כשרים'])  \n",
        "  support_arr.append(support_party) \n",
        "\n",
        "count = 0\n",
        "for j in range(4):\n",
        "  for k in range(4):\n",
        "    if count < 13:\n",
        "      sc = ax[j, k].scatter(first_n, second_n, c = support_arr[count], s = 3)\n",
        "      ax[j, k].set_title(correction_names_passed[count], fontsize=24, color=\"blue\")\n",
        "      ax[j, k].set_xlabel('first pca', fontsize=16)\n",
        "      ax[j, k].set_ylabel('second pca', fontsize=16)\n",
        "    count+=1\n",
        "\n",
        "plt.colorbar(sc)  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5KtPrFfrW76"
      },
      "source": [
        "First party - \"Po\"\n",
        "\n",
        "We can see that who votes to \"Po\" have better social-economic and it used to be from very high soceity to middle society - Bur we can't see Kalpi's support \"Po\", Because we know \"Po\" is a very big party we can conclude taht there is a correlation between living in high society city to vote \"Po\".\n",
        "But also we can see it is not very yellow so it means the support in thode kalpis are not by a large majority\n",
        "\n",
        "Second party - \"Vaadam\"\n",
        "\n",
        "In this party we can see more yellows points that means first that there are citis that have a absolut majority with support to this party.\n",
        "Also we can conclude that in the cities there's majority to \"vaadam\" there is low society-economic.\n",
        "And also we can see that \"Vaadam\" are far from lots of the kalpi and it means it is kind of minority population."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mw5-G5CgKnn"
      },
      "source": [
        "**Question 1:**\n",
        "\n",
        "Section A:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OiUX-gnf9wh"
      },
      "source": [
        "pcs = pd.DataFrame(pca.components_).T\n",
        "pow_pcs = pcs**2\n",
        "sqrt_pcs = np.sqrt(pow_pcs.sum())\n",
        "pcs = pcs.div(sqrt_pcs)\n",
        "ax = plt.subplot()\n",
        "first = pcs[0]\n",
        "second = pcs[1]\n",
        "ax.bar(np.arange(39),first , color = \"black\", width = 0.5)\n",
        "ax.bar(np.arange(39) + 0.5, second, color = \"green\", width = 0.5)\n",
        "plt.xticks(np.arange(39))\n",
        "ax.set_xticklabels(correction_names, rotation='vertical')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjzExLfAoZuS"
      },
      "source": [
        "**Question 1:**\n",
        "\n",
        "Section B:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6qBPLY0gBwc"
      },
      "source": [
        "pca = PCA()\n",
        "pca_5 = pca.fit_transform(df_2021.T)\n",
        "var_pca = pca.explained_variance_\n",
        "plt.bar(np.arange(39), var_pca / sum(var_pca))\n",
        "plt.xlabel('components')\n",
        "plt.ylabel('explained variance');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSeSAfHuv4px"
      },
      "source": [
        "**Question 2:**\n",
        "\n",
        "Section A:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP32S5xKp_4w"
      },
      "source": [
        "total_votes_2021 = parties_votes_percents(df_2021, 0.035)  # total votes for each party\n",
        "names_2021 = total_votes.keys() # largest parties\n",
        "total_votes_2020 = parties_votes_percents(df_2020, 0.035)  # total votes for each party\n",
        "names_2020 = total_votes.keys() # largest parties\n",
        "# Data with only the largest parties:\n",
        "df_2021 = df_2021[names]\n",
        "df_cities = df_2021\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8gxMyyz6ypb"
      },
      "source": [
        "Section B:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Jq6bqCxFz4"
      },
      "source": [
        "#reset\n",
        "df_2020_ = df_2020_raw[['בזב', 'סמל יישוב', 'בזב']].reset_index()\n",
        "df_2021_ = df_2021_raw[['בזב', 'סמל יישוב', 'בזב']].reset_index()\n",
        "\n",
        "join_df = df_2020_index.set_index('סמל ישוב').join(df_2020_index.set_index('סמל ישוב'))\n",
        "df_2020_raw.index = join_df['שם ישוב']\n",
        "\n",
        "df_2021_sorted = df_2021_raw.sort_index()\n",
        "df_2020_sorted = df_2020_raw.sort_index()\n",
        "df_m = pd.concat([df_2021_sorted, df_2020_sorted])\n",
        "sum_column = df_m.sum(axis = 1)\n",
        "df_m = df_m.div(sum_column) #Normlized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPzcUXf368ez"
      },
      "source": [
        "We can notice there is an linear growing but also there is point of getting down."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ0Gvm8yzodS"
      },
      "source": [
        "kosher = pd.concat([df_2021_raw['כשרים'], df_2020_raw['כשרים']])\n",
        "s_kosher = kosher / max(kosher)\n",
        "list_2020 = [20] * df_2020_raw.shape[0]\n",
        "list_2021 = [21] * df_2021_raw.shape[0]\n",
        "Y = list_2020 + list_2021\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "pca_6 = pca.fit_transform(df_m)\n",
        "fig, ax = plt.subplots(figsize=(20,14))\n",
        "first = pca_6[:, 0]\n",
        "second = pca_6[:, 1]\n",
        "scatter = ax.scatter(first, second, s = s_kosher, c = Y)\n",
        "ax.set_xlabel('pca first')\n",
        "ax.set_ylabel('pca second')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaAWBSV77dFj"
      },
      "source": [
        "Helper Functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-vxKU8p17Xk"
      },
      "source": [
        "def dist_x_y(d):\n",
        "    dx = d[0][0] - d[1][0]\n",
        "    dy = d[0][1] - d[1][1]\n",
        "    return dx, dy\n",
        "\n",
        "def calculate_top(df, pca, n):\n",
        "  pow_distance = (pca[: n] - pca[n : (2*n)])**2\n",
        "  largest_3 = pow_distance.sum(axis = 1)).nlargest(3).keys()\n",
        "  return df.index[largest_3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRgXd1087iVU"
      },
      "source": [
        "Section C:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUFlnNZo0hm3"
      },
      "source": [
        "MORE_THEN = 10000\n",
        "cities_more_then = kosher[kosher >= MORE_THEN]\n",
        "for city in cities_more_then.index:\n",
        "  city = df_m.index.iloc[city]\n",
        "  d = pca_6[city]\n",
        "  dx, dy = dist_x_y(d)\n",
        "  plt.arrow(d[1][0], d[1][1], dx, dy, width = 1/1000, head_length=1/10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEGNn6VK7wvj"
      },
      "source": [
        "Section D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tBZdFHXzpWS"
      },
      "source": [
        "n = df_2021_raw.shape[0]\n",
        "top_three = calculate_top(df_2021_raw, pca_6, n)\n",
        "fig, ax = plt.subplots(figsize=(22,16))\n",
        "first = pca_6[:, 0]\n",
        "second = pca_6[:, 1]\n",
        "scatter = ax.scatter(first, second, s = size, c = year)\n",
        "ax.set_xlabel('pca first')\n",
        "ax.set_ylabel('pca second')\n",
        "\n",
        "for city in top_3:\n",
        "  city = df_m.index.iloc[city]\n",
        "  d = pca_6[city]\n",
        "  dx, dy = dist_x_y(d)\n",
        "  plt.arrow(d[1][0], d[1][1], dx, dy, width = 1/1000, head_length=1/10)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}